#!/bin/bash

# Defaults
# Notes : 
# userdata is a directory created by the PG SCL image when the DB is first initialized on pod
# latest is a symlink created by the backup jobscript pointing to the latest successful backup directory

BACKUP_VERSION=${BACKUP_VERSION:-latest}
PG_SVC_NAME=${PG_SVC_NAME:-postgresql}
PV_BACKUP_DIR=${PV_BACKUP_DIR:-/backups}
PV_BACKUP_DATADIR="${PV_BACKUP_DIR}/${BACKUP_VERSION}"
PV_RESTORE_DIR=${PV_RESTORE_DIR:-/restore}
PV_RESTORE_DATADIR="${PV_RESTORE_DIR}/userdata"
TIMESTAMP=$(date +%Y%m%dT%H%M%S)

# Check if DB service is online, exit if true

echo "== Checking ${PG_SVC_NAME} status =="
pg_isready -h ${PG_SVC_NAME}

[ "$?" -eq "0" ] && echo "ERROR: PG service MUST BE OFFLINE before a database restore is attempted, exiting.." && exit 1

# Check backup source and destination volumes, also ensure dest is writable

[[ ! -d ${PV_BACKUP_DATADIR} ]] && echo "ERROR: Could not access ${PV_BACKUP_DATADIR}, please check volumes, exiting.." && exit 1
[[ ! -d ${PV_RESTORE_DIR} ]] && echo "ERROR: Could not access ${PV_RESTORE_DIR}, please check volumes, exiting.." && exit 1
[[ ! -w ${PV_RESTORE_DIR} ]] && echo "ERROR: ${PV_RESTORE_DIR} is not writable, please check volumes, exiting.." && exit 1

# Check destination for existing data, if data is found rename dir

echo "== Checking for existing PG data =="
if [[ -d ${PV_RESTORE_DATADIR} ]]; then
  echo "Existing data found at : ${PV_RESTORE_DATADIR}"
  mv ${PV_RESTORE_DATADIR} ${PV_RESTORE_DIR}/userdata_${TIMESTAMP}
  echo "Existing data moved to : ${PV_RESTORE_DIR}/userdata_${TIMESTAMP}"
else
  echo "No existing PGDATA dir was found at : ${PV_RESTORE_DATADIR}"
fi

echo "== Starting MIQ DB restore =="
echo "Current time is : $(date)"

mkdir ${PV_RESTORE_DATADIR}
tar -xzf ${PV_BACKUP_DATADIR}/base.tar.gz -C ${PV_RESTORE_DATADIR} --checkpoint=500

[[ $? -ne 0 ]] && echo "ERROR: DB restore exited with abnormal status, please check job logs" && exit 1

chmod 700 ${PV_RESTORE_DATADIR}
echo "Sucessfully finished DB restore : $(date)"
